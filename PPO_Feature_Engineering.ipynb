{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMrpFZuImk+J5zhqAPBlZNB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChrizzBln89/ChrizzBln89/blob/main/PPO_Feature_Engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weYyapenN81J",
        "outputId": "aa496296-08ec-4c57-d148-f87cdb762c50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "Google Drive erfolgreich verbunden.\n",
            "Lade Rohdaten von: /content/drive/MyDrive/data/PPO_portfolio_optimization/sp500_20_years_data.csv\n",
            "Rohdaten erfolgreich geladen.\n",
            "Ein unerwarteter Fehler ist aufgetreten: 'Adj Close'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# --- 1. Google Drive verbinden ---\n",
        "try:\n",
        "    drive.mount('/content/drive/')\n",
        "    print(\"Google Drive erfolgreich verbunden.\")\n",
        "except Exception as e:\n",
        "    print(f\"Fehler beim Verbinden mit Google Drive: {e}\")\n",
        "\n",
        "# --- 2. Pfade definieren ---\n",
        "BASE_DIR = '/content/drive/MyDrive/data/PPO_portfolio_optimization'\n",
        "INPUT_CSV = os.path.join(BASE_DIR, 'sp500_20_years_data.csv')\n",
        "OUTPUT_NPY = os.path.join(BASE_DIR, 'sp500_features_V1.npy')\n",
        "\n",
        "print(f\"Lade Rohdaten von: {INPUT_CSV}\")\n",
        "\n",
        "# --- 3. Rohdaten laden ---\n",
        "try:\n",
        "    # header=[0, 1] für MultiIndex-Spalten (z.B. 'Adj Close' -> 'AAPL')\n",
        "    data = pd.read_csv(INPUT_CSV, header=[0, 1], index_col=0, parse_dates=True)\n",
        "    print(\"Rohdaten erfolgreich geladen.\")\n",
        "\n",
        "    # --- 4. Ticker und Daten extrahieren ---\n",
        "    adj_close = data['Adj Close']\n",
        "    volume = data['Volume']\n",
        "\n",
        "    # Bereinigung: Entferne den S&P 500 Index ('^GSPC')\n",
        "    if '^GSPC' in adj_close.columns:\n",
        "        adj_close = adj_close.drop(columns='^GSPC')\n",
        "    if '^GSPC' in volume.columns:\n",
        "        volume = volume.drop(columns='^GSPC')\n",
        "\n",
        "    # Sicherstellen, dass die Spalten übereinstimmen\n",
        "    shared_tickers = adj_close.columns.intersection(volume.columns)\n",
        "    adj_close = adj_close[shared_tickers]\n",
        "    volume = volume[shared_tickers]\n",
        "\n",
        "    print(f\"Verarbeite {len(shared_tickers)} Ticker (nach Bereinigung).\")\n",
        "\n",
        "    # --- 5. Features berechnen ---\n",
        "    # (DataFrames behalten den Zeitindex und die Ticker-Namen)\n",
        "\n",
        "    # Feature 1: Log Returns\n",
        "    f1_log_returns = np.log(adj_close / adj_close.shift(1))\n",
        "\n",
        "    # Feature 2: Volatilität (Rollierende 20-Tage-Standardabweichung)\n",
        "    f2_volatility = f1_log_returns.rolling(window=20).std()\n",
        "\n",
        "    # Feature 3: Volumen-Verhältnis (Normalisiertes Volumen)\n",
        "    volume_rolling_mean = volume.rolling(window=20).mean()\n",
        "    f3_volume_ratio = volume / volume_rolling_mean\n",
        "\n",
        "    print(\"Features berechnet: Log Returns, Volatilität, Volumen-Verhältnis.\")\n",
        "\n",
        "    # --- 6. 3D-Tensor erstellen ---\n",
        "    # Liste unserer 2D-Feature-DataFrames\n",
        "    features_list = [f1_log_returns, f2_volatility, f3_volume_ratio]\n",
        "\n",
        "    # Wandle DataFrames in NumPy-Arrays um (.values) und staple sie\n",
        "    # entlang einer neuen dritten Achse (axis=2).\n",
        "    # Das Ergebnis hat die Form (Tage, Assets, Features)\n",
        "    feature_tensor_3d = np.stack([f.values for f in features_list], axis=2)\n",
        "\n",
        "    # --- 7. NaNs (Not a Number) bereinigen ---\n",
        "    # Ersetze NaNs (von rolling/shift) und unendliche Werte durch 0.0\n",
        "    feature_tensor_3d = np.nan_to_num(feature_tensor_3d, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "    print(f\"3D-Tensor erfolgreich erstellt.\")\n",
        "    print(f\"Finale Tensor-Form: {feature_tensor_3d.shape}\")\n",
        "    print(\"(Tage, Assets, Features)\")\n",
        "\n",
        "    # --- 8. 3D-Tensor als .npy speichern ---\n",
        "    np.save(OUTPUT_NPY, feature_tensor_3d)\n",
        "\n",
        "    print(f\"--- ERFOLG ---\")\n",
        "    print(f\"Feature-Tensor gespeichert unter: {OUTPUT_NPY}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"FEHLER: Die Datei {INPUT_CSV} wurde nicht gefunden.\")\n",
        "except Exception as e:\n",
        "    print(f\"Ein unerwarteter Fehler ist aufgetreten: {e}\")"
      ]
    }
  ]
}